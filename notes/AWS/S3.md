## What is it? 
Object storage service that offers: 
- scalability 
- data availability 
- security 
- performance 

latency
- time it takes for data to pass from 1 point on network to another 

What is latency-sensitive 
- real time app where high or variable latency will negatively affect app performance 

[Definitions ](https://www.redhat.com/en/topics/edge-computing/latency-sensitive-applications#:~:text=TLDR%3B%20A%20latency%2Dsensitive%20application,window%2C%20often%20measured%20in%20microseconds.)
- **Latency** is the time from when an event occurs to when that event is handled by a system; the easiest way of looking at it is the time it takes to go from point A to point B.
- **Bandwidth** (or network bandwidth) is the amount of data that can be transported in a given period of time; this is usually megabits or gigabits per second. The actual amount of data transported in a given time is called throughput. High bandwidth (or high throughput) and low latency can sometimes be considered a tradeoff. It is difficult to achieve both simultaneously.
- **Packets** are the data elements being transported.
- **Jitter** is variability in latency, usually when the consistency of the network communication is dropped or intermittently slow.
- **Real time** means that an operation is performed within a specific, defined amount of time (usually measured in milli or microseconds). Real time is often misunderstood to mean "real fast"; real time is more about determinism, which means the operation is guaranteed within a given set of time constraints regardless of other operations or load. With real time processing, each transaction is discrete, unlike batch processing, which collects multiple transactions together.
- **Edge nodes** generally refer to any device or server where edge computing can take place.



## How it Works  

- Achieves high availability by replicating data across multiple servers within AWS data centers
- Concurrent applications (if multiple clients are writing to the same item at the same time)
	- Last write wins BUT due to network latency, it's unpredictable what the Read will be if Write2 happens **at same time as** Read1 or **happens right before** Read1 happens 
	- ![[Pasted image 20241003145032.png]]
- 


## WHY S3? 
**Why would you even use S3? don't servers have hard drives? can't you just save things on the server?**
- S3 is an object storage service that serves the file for you so that you don't have to use your own server. 
- **Own hard drive - it's not as scalable and risky security** 
- Scalability: 
	- It's dynamic for storage. Don't have to worry about managing space, just pay for what you use. Vs in hard drive, will have to worry about the size of the hard drive. 
- Reliability: 
	- S3 handles making backups and security and can replicate files across many servers 
- If you have your own servers, would have to handle what happens if multiple clients are reading/writing at the same time 
- Handles data sync for you 


**Benefits of object storage system are that (even though all this could be manually managed on hard drives), it helps with:** 
- Scalability: where you don't have to worry about managing space, just pay for what you use. Vs in hard drive, you will have to worry about the size of the hard drive, and managing the storage. 
- Reliability and Data Sync: S3 can sync files across multiple servers and handle backups 
- Security: can manage permissions using AWS's IAM roles vs handling the authorizing and authenticating yourself 
- Load Balancing: determines what happens if multiple clients are reading/writing at the same time for you and ensures that the data is accessible even with heavy load 